{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d61ffe9e",
   "metadata": {},
   "source": [
    "# <center>CSE 4/546: Reinforcement Learning</center>\n",
    "## <center>Prof. Alina Vereshchaka</center>\n",
    "### <center>Assignment 1, Part 3</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1cf939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import gymnasium\n",
    "from gymnasium import spaces\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0db09cc",
   "metadata": {},
   "source": [
    "### Stock Trading Environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f827591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Stock Trading Environment.\n",
    "\"\"\"DON'T MAKE ANY CHANGES TO THE ENVIRONMENT.\"\"\"\n",
    "\n",
    "\n",
    "class StockTradingEnvironment(gymnasium.Env):\n",
    "    \"\"\"This class implements the Stock Trading environment.\"\"\"\n",
    "\n",
    "    def __init__(self, file_path, train=True, number_of_days_to_consider=10):\n",
    "        \"\"\"This method initializes the environment.\n",
    "\n",
    "        :param file_path: - Path of the CSV file containing the historical stock data.\n",
    "        :param train: - Boolean indicating whether the goal is to train or test the performance of the agent.\n",
    "        :param number_of_days_to_consider = Integer representing the number of days the for which the agent\n",
    "                considers the trend in stock price to make a decision.\"\"\"\n",
    "\n",
    "        self.file_path = file_path\n",
    "        self.stock_data = pd.read_csv(self.file_path)\n",
    "        self.train = train\n",
    "\n",
    "        # Splitting the data into train and test datasets.\n",
    "        self.training_stock_data = self.stock_data.iloc[:int(0.8 * len(self.stock_data))]\n",
    "        self.testing_stock_data = self.stock_data.iloc[int(0.8 * len(self.stock_data)):].reset_index()\n",
    "\n",
    "        self.observation_space = spaces.Discrete(4)\n",
    "        self.action_space = spaces.Discrete(3)\n",
    "\n",
    "        self.investment_capital = 100000  # This defines the investment capital that the agent starts with.\n",
    "        self.number_of_shares = 0  # This defines number of shares currently held by the agent.\n",
    "        self.stock_value = 0  # This defines the value of the stock currently held by the agent.\n",
    "        self.book_value = 0  # This defines the total value for which the agent bought the shares.\n",
    "        # This defines the agent's total account value.\n",
    "        self.total_account_value = self.investment_capital + self.stock_value\n",
    "        # List to store the total account value over training or evaluation.\n",
    "        self.total_account_value_list = []\n",
    "        # This defines the number of days for which the agent considers the data before taking an action.\n",
    "        self.number_of_days_to_consider = number_of_days_to_consider\n",
    "        # The maximum timesteps the agent will take before the episode ends.\n",
    "        if self.train:\n",
    "            self.max_timesteps = len(self.training_stock_data) - self.number_of_days_to_consider\n",
    "        else:\n",
    "            self.max_timesteps = len(self.testing_stock_data) - self.number_of_days_to_consider\n",
    "        # Initializing the number of steps taken to 0.\n",
    "        self.timestep = 0\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"This method resets the environment and returns the observation.\n",
    "\n",
    "        :returns observation: - Integer in the range of 0 to 3 representing the four possible observations that the\n",
    "                                agent can receive. The observation depends upon whether the price increased on average\n",
    "                                in the number of days the agent considers, and whether the agent already has the stock\n",
    "                                or not.\n",
    "\n",
    "         info: - A dictionary that can be used to provide additional implementation information.\"\"\"\n",
    "\n",
    "        self.investment_capital = 100000  # This defines the investment capital that the agent starts with.\n",
    "        self.number_of_shares = 0  # This defines number of shares currently held by the agent.\n",
    "        self.stock_value = 0  # This defines the value of the stock currently held by the agent.\n",
    "        self.book_value = 0  # This defines the total value for which the agent bought the shares.\n",
    "        # This defines the agent's total account value.\n",
    "        self.total_account_value = self.investment_capital + self.stock_value\n",
    "        # List to store the total account value over training or evaluation.\n",
    "        self.total_account_value_list = []\n",
    "        # Initializing the number of steps taken to 0.\n",
    "        self.timestep = 0\n",
    "\n",
    "        # Getting the observation vector.\n",
    "        if self.train:\n",
    "            # If the task is to train the agent the maximum timesteps will be equal to the number of days considered\n",
    "            # subtracted from the  length of the training stock data.\n",
    "            self.max_timesteps = len(self.training_stock_data) - self.number_of_days_to_consider\n",
    "\n",
    "            # Calculating whether the price increased or decreased/remained the same on the majority of days the agent\n",
    "            # considers.\n",
    "            price_increase_list = []\n",
    "            for i in range(self.number_of_days_to_consider):\n",
    "                if self.training_stock_data['Close'][self.timestep + 1 + i] \\\n",
    "                        - self.training_stock_data['Close'][self.timestep + i] > 0:\n",
    "                    price_increase_list.append(1)\n",
    "                else:\n",
    "                    price_increase_list.append(0)\n",
    "\n",
    "            if (np.sum(price_increase_list) / self.number_of_days_to_consider) >= 0.5:\n",
    "                price_increase = True\n",
    "            else:\n",
    "                price_increase = False\n",
    "\n",
    "            stock_held = False\n",
    "\n",
    "            # Observation vector that will be passed to the agent.\n",
    "            observation = [price_increase, stock_held]\n",
    "\n",
    "        else:\n",
    "            # If the task is to evaluate the trained agent's performance the maximum timesteps will be equal to the\n",
    "            # number of days considered subtracted from the  length of the testing stock data.\n",
    "            self.max_timesteps = len(self.testing_stock_data) - self.number_of_days_to_consider\n",
    "\n",
    "            # Calculating whether the price increased or decreased/remained the same on the majority of days the agent\n",
    "            # considers.\n",
    "            price_increase_list = []\n",
    "            for i in range(self.number_of_days_to_consider):\n",
    "                if self.testing_stock_data['Close'][self.timestep + 1 + i] \\\n",
    "                        - self.testing_stock_data['Close'][self.timestep + i] > 0:\n",
    "                    price_increase_list.append(1)\n",
    "                else:\n",
    "                    price_increase_list.append(0)\n",
    "\n",
    "            if (np.sum(price_increase_list) / self.number_of_days_to_consider) >= 0.5:\n",
    "                price_increase = True\n",
    "            else:\n",
    "                price_increase = False\n",
    "\n",
    "            stock_held = False\n",
    "\n",
    "            # Observation vector.\n",
    "            observation = [price_increase, stock_held]\n",
    "\n",
    "        if np.array_equal(observation, [True, False]):\n",
    "            observation = 0\n",
    "        if np.array_equal(observation, [True, True]):\n",
    "            observation = 1\n",
    "        if np.array_equal(observation, [False, False]):\n",
    "            observation = 2\n",
    "        if np.array_equal(observation, [False, True]):\n",
    "            observation = 3\n",
    "\n",
    "        info = None\n",
    "\n",
    "        return observation, info\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"This method implements what happens when the agent takes the action to Buy/Sell/Hold.\n",
    "\n",
    "        :param action: - Integer in the range 0 to 2 inclusive.\n",
    "\n",
    "        :returns observation: - Integer in the range of 0 to 3 representing the four possible observations that the\n",
    "                                agent can receive. The observation depends upon whether the price increased on average\n",
    "                                in the number of days the agent considers, and whether the agent already has the stock\n",
    "                                or not.\n",
    "                 reward: - Integer/Float value that's used to measure the performance of the agent.\n",
    "                 terminated: - Boolean describing whether the episode has terminated.\n",
    "                 truncated: - Boolean describing whether a truncation condition outside the scope of the MDP is satisfied.\n",
    "                 info: - A dictionary that can be used to provide additional implementation information.\"\"\"\n",
    "\n",
    "        # We give the agent a penalty for taking actions such as buying a stock when the agent doesn't have the\n",
    "        # investment capital and selling a stock when the agent doesn't have any shares.\n",
    "        penalty = 0\n",
    "\n",
    "        if self.train:\n",
    "            if action == 0:  # Buy\n",
    "                if self.number_of_shares > 0:\n",
    "                    penalty = -10\n",
    "                # Determining the number of shares the agent can buy.\n",
    "                number_of_shares_to_buy = math.floor(self.investment_capital / self.training_stock_data[\n",
    "                    'Open'][self.timestep + self.number_of_days_to_consider])\n",
    "                # Adding to the number of shares the agent has.\n",
    "                self.number_of_shares += number_of_shares_to_buy\n",
    "\n",
    "                # Computing the stock value, book value, investment capital and reward.\n",
    "                if number_of_shares_to_buy > 0:\n",
    "                    self.stock_value +=\\\n",
    "                        self.training_stock_data['Open'][self.timestep + self.number_of_days_to_consider] \\\n",
    "                        * number_of_shares_to_buy\n",
    "                    self.book_value += \\\n",
    "                        self.training_stock_data['Open'][self.timestep + self.number_of_days_to_consider]\\\n",
    "                        * number_of_shares_to_buy\n",
    "                    self.investment_capital -= \\\n",
    "                        self.training_stock_data['Open'][self.timestep + self.number_of_days_to_consider] \\\n",
    "                        * number_of_shares_to_buy\n",
    "\n",
    "                    reward = 1 + penalty\n",
    "\n",
    "                else:\n",
    "                    # Computing the stock value and reward.\n",
    "                    self.stock_value = \\\n",
    "                        self.training_stock_data['Open'][self.timestep + self.number_of_days_to_consider] \\\n",
    "                        * self.number_of_shares\n",
    "                    reward = -10\n",
    "\n",
    "            if action == 1:  # Sell\n",
    "                # Computing the investment capital, sell value and reward.\n",
    "                self.investment_capital += \\\n",
    "                    self.training_stock_data['Open'][self.timestep + self.number_of_days_to_consider] \\\n",
    "                    * self.number_of_shares\n",
    "                sell_value = self.training_stock_data['Open'][self.timestep + self.number_of_days_to_consider] \\\n",
    "                             * self.number_of_shares\n",
    "\n",
    "                if self.book_value > 0:\n",
    "                    reward = (sell_value - self.book_value) / self.book_value * 100\n",
    "                else:\n",
    "                    reward = -10\n",
    "\n",
    "                self.number_of_shares = 0\n",
    "                self.stock_value = 0\n",
    "                self.book_value = 0\n",
    "\n",
    "            if action == 2:  # Hold\n",
    "                # Computing the stock value and reward.\n",
    "                self.stock_value = self.training_stock_data['Open'][self.timestep + self.number_of_days_to_consider] \\\n",
    "                                   * self.number_of_shares\n",
    "\n",
    "                if self.book_value > 0:\n",
    "                    reward = (self.stock_value - self.book_value) / self.book_value * 100\n",
    "                else:\n",
    "                    reward = -1\n",
    "\n",
    "        else:\n",
    "            if action == 0:  # Buy\n",
    "                if self.number_of_shares > 0:\n",
    "                    penalty = -10\n",
    "                # Determining the number of shares the agent can buy.\n",
    "                number_of_shares_to_buy = math.floor(self.investment_capital / self.testing_stock_data[\n",
    "                    'Open'][self.timestep + self.number_of_days_to_consider])\n",
    "                # Adding to the number of shares the agent has.\n",
    "                self.number_of_shares += number_of_shares_to_buy\n",
    "\n",
    "                # Computing the stock value, book value, investment capital and reward.\n",
    "                if number_of_shares_to_buy > 0:\n",
    "                    self.stock_value += \\\n",
    "                        self.testing_stock_data['Open'][self.timestep + self.number_of_days_to_consider] \\\n",
    "                        * number_of_shares_to_buy\n",
    "                    self.book_value += \\\n",
    "                        self.testing_stock_data['Open'][self.timestep + self.number_of_days_to_consider] \\\n",
    "                        * number_of_shares_to_buy\n",
    "                    self.investment_capital -= \\\n",
    "                        self.testing_stock_data['Open'][self.timestep + self.number_of_days_to_consider] \\\n",
    "                        * number_of_shares_to_buy\n",
    "\n",
    "                    reward = 1 + penalty\n",
    "\n",
    "                else:\n",
    "                    # Computing the stock value and reward.\n",
    "                    self.stock_value = self.training_stock_data['Open'][\n",
    "                                           self.timestep + self.number_of_days_to_consider] * self.number_of_shares\n",
    "                    reward = -10\n",
    "\n",
    "            if action == 1:  # Sell\n",
    "                # Computing the investment capital, sell value and reward.\n",
    "                self.investment_capital += \\\n",
    "                    self.testing_stock_data['Open'][self.timestep + self.number_of_days_to_consider] \\\n",
    "                    * self.number_of_shares\n",
    "                sell_value = self.training_stock_data['Open'][self.timestep + self.number_of_days_to_consider] \\\n",
    "                             * self.number_of_shares\n",
    "\n",
    "                if self.book_value > 0:\n",
    "                    reward = (sell_value - self.book_value) / self.book_value * 100\n",
    "                else:\n",
    "                    reward = -10\n",
    "\n",
    "                self.number_of_shares = 0\n",
    "                self.stock_value = 0\n",
    "                self.book_value = 0\n",
    "\n",
    "            if action == 2:  # Hold\n",
    "                # Computing the stock value and reward.\n",
    "                self.stock_value = self.testing_stock_data['Open'][self.timestep + self.number_of_days_to_consider] \\\n",
    "                                   * self.number_of_shares\n",
    "\n",
    "                if self.book_value > 0:\n",
    "                    reward = (self.stock_value - self.book_value) / self.book_value * 100\n",
    "                else:\n",
    "                    reward = -1\n",
    "\n",
    "        # Determining if the agent currently has shares of the stock or not.\n",
    "        if self.number_of_shares > 0:\n",
    "            stock_held = True\n",
    "        else:\n",
    "            stock_held = False\n",
    "\n",
    "        # Getting the observation vector.\n",
    "        if self.train:\n",
    "            # If the task is to train the agent the maximum timesteps will be equal to the number of days considered\n",
    "            # subtracted from the  length of the training stock data.\n",
    "            self.max_timesteps = len(self.training_stock_data) - self.number_of_days_to_consider\n",
    "\n",
    "            # Calculating whether the price increased or decreased/remained the same on the majority of days the agent\n",
    "            # considers.\n",
    "            price_increase_list = []\n",
    "            for i in range(self.number_of_days_to_consider):\n",
    "                if self.training_stock_data['Close'][self.timestep + 1 + i] \\\n",
    "                        - self.training_stock_data['Close'][self.timestep + i] > 0:\n",
    "                    price_increase_list.append(1)\n",
    "                else:\n",
    "                    price_increase_list.append(0)\n",
    "\n",
    "            if (np.sum(price_increase_list) / self.number_of_days_to_consider) >= 0.5:\n",
    "                price_increase = True\n",
    "            else:\n",
    "                price_increase = False\n",
    "\n",
    "            # Observation vector.\n",
    "            observation = [price_increase, stock_held]\n",
    "\n",
    "        else:\n",
    "            # If the task is to evaluate the trained agent's performance the maximum timesteps will be equal to the\n",
    "            # number of days considered subtracted from the  length of the testing stock data.\n",
    "            self.max_timesteps = len(self.testing_stock_data) - self.number_of_days_to_consider\n",
    "\n",
    "            # Calculating whether the price increased or decreased/remained the same on the majority of days the agent\n",
    "            # considers.\n",
    "            price_increase_list = []\n",
    "            for i in range(self.number_of_days_to_consider):\n",
    "                if self.testing_stock_data['Close'][self.timestep + 1 + i] \\\n",
    "                        - self.testing_stock_data['Close'][self.timestep + i] > 0:\n",
    "                    price_increase_list.append(1)\n",
    "                else:\n",
    "                    price_increase_list.append(0)\n",
    "\n",
    "            if (np.sum(price_increase_list) / self.number_of_days_to_consider) >= 0.5:\n",
    "                price_increase = True\n",
    "            else:\n",
    "                price_increase = False\n",
    "\n",
    "            # Observation vector.\n",
    "            observation = [price_increase, stock_held]\n",
    "\n",
    "        self.timestep += 1  # Increasing the number of steps taken by the agent by 1.\n",
    "\n",
    "        if np.array_equal(observation, [True, False]):\n",
    "            observation = 0\n",
    "        if np.array_equal(observation, [True, True]):\n",
    "            observation = 1\n",
    "        if np.array_equal(observation, [False, False]):\n",
    "            observation = 2\n",
    "        if np.array_equal(observation, [False, True]):\n",
    "            observation = 3\n",
    "\n",
    "        # Computing the total account value.\n",
    "        self.total_account_value = self.investment_capital + self.stock_value\n",
    "        # Appending the total account value of the list to plot the graph.\n",
    "        self.total_account_value_list.append(self.total_account_value)\n",
    "\n",
    "        # The episode terminates when the maximum timesteps have been reached.\n",
    "        terminated = True if (self.timestep >= self.max_timesteps) \\\n",
    "            else False\n",
    "        truncated = False\n",
    "        info = {}\n",
    "\n",
    "        return observation, reward, terminated, truncated, info\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        \"\"\"This method renders the agent's total account value over time.\n",
    "\n",
    "        :param mode: 'human' renders to the current display or terminal and returns nothing.\"\"\"\n",
    "\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.plot(self.total_account_value_list, color='lightseagreen', linewidth=7)\n",
    "        plt.xlabel('Days', fontsize=32)\n",
    "        plt.ylabel('Total Account Value', fontsize=32)\n",
    "        plt.title('Total Account Value over Time', fontsize=38)\n",
    "        plt.grid()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca06c6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: You can adjust the parameter 'number_of_days_to_consider'. To train the agent, set 'train=True', and to evaluate the agent, set 'train=False'.\n",
    "\n",
    "stock_trading_environment = StockTradingEnvironment(file_path='./NVDA.csv', train=True, number_of_days_to_consider=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### TO DO: Implement the Q-learning algorithm"
   ],
   "id": "445893f5bea20c56"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff10c21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
